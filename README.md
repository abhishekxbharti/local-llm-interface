# Local LLM Interface

A clean, minimal chat interface for Ollama.

## Setup

1. Install [Ollama](https://ollama.com/download)
2. Install dependencies and run:

```bash
pnpm install
pnpm dev
```

3. Open [localhost:3000](http://localhost:3000)

## Configuration

If Ollama isn't at the default address, create `.env.local`:

```
OLLAMA_URL="http://localhost:11434"
```
